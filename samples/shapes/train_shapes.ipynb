{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     12\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      2\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 6\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'mrcnn_mask_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'rpn_class_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 2\n",
    "    IMAGES_PER_GPU = 6\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                                shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y-s),\n",
    "                                (x-s/math.sin(math.radians(60)), y+s),\n",
    "                                (x+s/math.sin(math.radians(60)), y+s),\n",
    "                                ]], dtype=np.int32)\n",
    "            cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height//4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y-s, x-s, y+s, x+s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyoAAACnCAYAAAD+D6hcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAC6hJREFUeJzt3X/I9Xddx/HXe20O+7lJqQMDm7DSETHEWU3EaFJbzMFKLVKhVizaBNmilpSVs6Y2wj82I2KuoESjxpg0MOa0uldzd3f7I+9oJWZRzpZ0o4vWfuinP873omvXrvu+ruv2nOu8zzmPB9xc53zPd9/v59x8bzjP+32+92qMEQAAgE7OWPYCAAAAdhIqAABAO0IFAABoR6gAAADtCBUAAKAdoQIAALSzMaFSVS+uqnt3bPv0aRznnqq6aHp8eVWdqKqanr+3qt68j2PcVFX/sn09VXVRVd1fVX9RVfdV1fnT9vOnbZ+oqo9X1YtOcdyXVNWxqvrvqnrVtu3vq6oHpl83btv+i1V1tKoerKrrD/p7wXJV1TlV9ZaTvPa+qvqWOZ3nWX92AAAWbWNCZY6OJLlkenxJkmNJLtz2/C/3cYz3J/m+HdseSfKDY4xXJ7klya9N2382ye1jjNck+f0kbz3FcR9J8tokf7xj+21jjO9O8r1JrpyC5huS/GSSre0/U1Vft4+108c5SZ4VKlX1NWOMt40x/nMJawIAmAuhskNVvb+q3lJVZ1TVR6vqlTt2OZJka1rxXUl+O8mrqursJC8YY3x2r3OMMR5J8pUd2z4/xnhsevpEkqenx8cz+0CaJOcmebSqzq6qI1X1HVX1wmkicu4Y43/GGP+1y/n+afr5lem4X07yeJLPJXnu9OvxJE/ttXZauT7Jy6dp29Gq+r2qujvJG6ZtL6qqb66qj03P76+qC5Jk2vd3q+pPp0nb86ft11fV31TVH07HfPH2E1bVt07/zX3Tz7lMbQAAdjpz2Qs4ZC+vqk/ssc/1Se7LbDrysTHGJ3e8/mCSD1TVWUlGZhOUW5J8KsnRJKmq70ly8y7HfucY475TnXyaarwrydXTpnuTfLSqrk5ydpKLxxhPTM/vSPLFJG8bY5zY432lqn48yWe2Yqqq7knycGbB+q4xxpN7HYNWfivJy8YYl1bVryY5b4zxuiSpqmumfb6Y5LIxxpNVdVmSGzObpCXJ8THGT1fV2zOLmz9K8uYkr0jytUk+s8s5fzPJTWOMB6rqyiS/kOTnFvT+AIANtmmhcmyMcenWk93uURlj/G9V3ZHkvUnOO8nrjya5KslDY4xHq+qFmU1Zjkz7/HWS1xx0cVP8fDjJe8YYfz9tfk+SXxpj3FlVP5bkN5JcO8Z4uKr+Ocnzxhh/tY9jX5rkJ5JcMT2/IMkPJzk/s1D586q6a4zx7wddN23sdh2ck+S26Rp9TpLHtr12bPr5r0lekuTbknxqjPF0ki9V1T/scrzvTPLu6basM5Mc+D4v2K6qrkvyI0k+Pcb4qWWvh83kOmTZXIO727RQ2VNVnZfZNOOmzKJgt5vMjyT5+SRvn55/LsnrMwuB05qoVNUZSf4gyV1jjLu2v5TkC9PjR5M8b9r/tUnOSvKFqnrdGOPuU7ynV07v57IxxuPbjvvYGOOJaZ8nknz9yY5BS0/mmX+Gv7zLPm/KLKhvrqrL88zreWx7XEk+m+TCqjozs68Dfvsuxzue5OYxxkNJUlXPOf3lQzLGuDXJrcteB5vNdciyuQZ3J1S2mWLhjsy+SvVAVX2oqi4fY9yzY9cjSW5I8sD0/P4kV2b29a89JypTNf9okpdO/5rSNUkuSvJDSV5QVW9K8ndjjLdm9jWw36mqpzMLk2um+wl+PckPZHbPyb1V9bdJvpTkziQvy+wD5z1jjF9Jcvt06rumvwm/YYxxbLq35YHMPqR+fIzx8Gn8trE8n0/yeFX9SZLnZ/fpxp8l+WBVvTqzyDipMcZ/VNUHk3wyyT8m+bfMYmh7jNyQ2YRmK2o/kFlgAwDMVY0x9t4L2AhVddYY46mq+sYkDyW5YIyx26QGAGChTFSA7W6squ9P8k1JflmkAADLYqICAAC04/+jAgAAtCNUAACAdlrco3Lujff7/tkGOfHuS2rZa9jNcy+6znW4QR5/6FbXIUvX8Tp0DW6Wjtdg4jrcNCe7Dk1UAACAdoQKAADQjlABAADaESoAAEA7QgUAAGhHqAAAAO0IFQAAoB2hskQXv7HlP13Ohrn6HdcuewkAAM8iVJZkK1LECsu0FSliBQDoRqgAAADtCJUl2DlFMVVhGXZOUUxVAIBOhAoAANCOUDlkJ5uemKpwmE42PTFVAQC6ECqHSIzQgRgBAFaBUDkk+4mUi99YYoaF2k+kXP2Oa8UMALB0QgUAAGhHqByCg05JTFVYhINOSUxVAIBlEioLJjroQHQAAKtGqDQlcOhA4AAAyyJUFkhs0IHYAABW0dqFyvGrPrLsJcyN0FldJ47euuwlzI3QAQCWYa1CZStSOsTKvCJDrKyerUjpECvzigyxAgActrUKlS7EBR2ICwBgla1NqOyconSYqsyL8FkdO6coHaYq8yJ8AIDDtDah0oWooANRAQCsurUIlZNNT0xVOEwnm56YqgAAHNxahEoXi44JscJ+LDomxAoAcBhWPlT2mpoc1lRFRGy2vaYmhzVVEREAwLpY+VDZD18BowNfAQMA2L+NCJVFEw90IB4AgHWy0qFykEmJqQqLcpBJiakKAMD+rHSodCAa6EA0AADrZmVD5XQmJPOeqogUTmdCMu+pikgBANbRyobKphNJdCCSAIBFWclQ+WomI+t0rwrL9dVMRtbpXhUAgEVYuVCZR2isS6yYqizPPEJjXWLFVAUAWISVC5UuRAIdiAQAYF2tVKjMcxJiqsLpmuckxFQFAGB3KxUqXYgDOhAHAMA6W5lQWcQE5HSO2TFSOq5pXS1iAnI6x+wYKR3XBACsrpUJFU5NrNCBWAEA5mUlQmWR95Mc5NhiYLMt8n6SgxxbDAAAm6B9qBzGTe9urGcvh3HTuxvrAQD+X/tQ6UIE0IEIAAA2RetQOcxJx6nOtUqRskprXRWHOek41blWKVJWaa0AQE9tQ2UZX8fa7Zyr+MF/Fdfc1TK+jrXbOVfxg/8qrhkA6KNtqCyL+1XowP0qAMCmaxkqXWLBh/3N1iUWfNgHADZRu1DpECnHr/rIWkTKOryHZekQKSeO3roWkbIO7wEAOHztQgUAAKBVqHSYpmy546m7l72EuTBVObgO05Qtt1zx0mUvYS5MVQCAg2oVKiyGWKEDsQIAHESbUOk0TdmyLlMV9q/TNGXLukxVAAAOok2odLUusWKqstrWJVZMVQCA/WoRKh2nKWyejtMUAIBN1SJUujNVoQNTFQBgkwgVAACgHaGyT6YqdGCqAgBsijOXvYBV8uCHx7KXALn9nbctewkAAAtnonIAbvqnAzf9AwCboMVE5cI7r1j2EiDnvuK6ZS8BAICJiQoAANCOUAEAANoRKgAAQDtCBQAAaEeoAAAA7QgVAACgHaECAAC0I1QAAIB2hAoAANCOUAEAANoRKgAAQDtCBQAAaEeoAAAA7QgVAACgHaECAAC0I1QAAIB2hAoAANCOUAEAANoRKgAAQDtCBQAAaEeoAAAA7QgVAACgHaECAAC0I1QAAIB2hAoAANCOUAEAANoRKgAAQDtCBQAAaEeoAAAA7QgVAACgHaECAAC0I1QAAIB2hAoAANCOUAEAANoRKgAAQDtCBQAAaEeoAAAA7QgVAACgHaECAAC0I1QAAIB2hAoAANCOUAEAANoRKgAAQDtCBQAAaEeoAAAA7QgVAACgHaECAAC0I1QAAIB2hAoAANCOUAEAANoRKgAAQDtCBQAAaEeoAAAA7QgVAACgHaECAAC0I1QAAIB2hAoAANCOUAEAANoRKgAAQDtCBQAAaEeoAAAA7QgVAACgnRpjLHsNAAAAz2CiAgAAtCNUAACAdoQKAADQjlABAADaESoAAEA7QgUAAGhHqAAAAO0IFQAAoB2hAgAAtCNUAACAdoQKAADQjlABAADaESoAAEA7QgUAAGhHqAAAAO0IFQAAoB2hAgAAtCNUAACAdoQKAADQjlABAADaESoAAEA7QgUAAGhHqAAAAO38HzqNz+RsufouAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/fothar/cluster_segmentation_redesign/logs/shapes20190102T1011/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fothar/.local/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/fothar/.local/lib/python3.5/site-packages/keras/engine/training.py:2033: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 129s 1s/step - loss: 1.8915 - rpn_class_loss: 0.0302 - rpn_bbox_loss: 0.6002 - mrcnn_class_loss: 0.3723 - mrcnn_bbox_loss: 0.3575 - mrcnn_mask_loss: 0.5312 - val_loss: 1.0680 - val_rpn_class_loss: 0.0140 - val_rpn_bbox_loss: 0.4468 - val_mrcnn_class_loss: 0.1333 - val_mrcnn_bbox_loss: 0.1359 - val_mrcnn_mask_loss: 0.3379\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 0.9581 - rpn_class_loss: 0.0147 - rpn_bbox_loss: 0.4121 - mrcnn_class_loss: 0.1738 - mrcnn_bbox_loss: 0.1260 - mrcnn_mask_loss: 0.2316 - val_loss: 0.9019 - val_rpn_class_loss: 0.0116 - val_rpn_bbox_loss: 0.4102 - val_mrcnn_class_loss: 0.1787 - val_mrcnn_bbox_loss: 0.1082 - val_mrcnn_mask_loss: 0.1932\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 0.7906 - rpn_class_loss: 0.0133 - rpn_bbox_loss: 0.3956 - mrcnn_class_loss: 0.1410 - mrcnn_bbox_loss: 0.0937 - mrcnn_mask_loss: 0.1471 - val_loss: 0.7998 - val_rpn_class_loss: 0.0123 - val_rpn_bbox_loss: 0.4388 - val_mrcnn_class_loss: 0.1442 - val_mrcnn_bbox_loss: 0.0812 - val_mrcnn_mask_loss: 0.1233\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=3, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 3. LR=0.0001\n",
      "\n",
      "Checkpoint Path: /home/fothar/cluster_segmentation_redesign/logs/shapes20190102T1011/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fothar/.local/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/fothar/.local/lib/python3.5/site-packages/keras/engine/training.py:2033: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.6810 - rpn_class_loss: 0.0124 - rpn_bbox_loss: 0.3703 - mrcnn_class_loss: 0.1125 - mrcnn_bbox_loss: 0.0690 - mrcnn_mask_loss: 0.1168 - val_loss: 0.6976 - val_rpn_class_loss: 0.0123 - val_rpn_bbox_loss: 0.3881 - val_mrcnn_class_loss: 0.1073 - val_mrcnn_bbox_loss: 0.0770 - val_mrcnn_mask_loss: 0.1130\n"
     ]
    }
   ],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=4, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "# model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "# model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fothar/.local/lib/python3.5/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "Loading weights from  /home/fothar/cluster_segmentation_redesign/logs/shapes20190102T1011/mask_rcnn_shapes_0004.h5\n",
      "Re-starting from epoch 4\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_image           shape: (128, 128, 3)         min:   27.00000  max:  250.00000  uint8\n",
      "image_meta               shape: (16,)                 min:    0.00000  max:  128.00000  int64\n",
      "gt_class_id              shape: (1,)                  min:    3.00000  max:    3.00000  int32\n",
      "gt_bbox                  shape: (1, 4)                min:   37.00000  max:  128.00000  int32\n",
      "gt_mask                  shape: (128, 128, 1)         min:    0.00000  max:    1.00000  bool\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (128, 128, 3)         min:   27.00000  max:  250.00000  uint8\n",
      "molded_images            shape: (1, 128, 128, 3)      min:  -89.80000  max:  146.10000  float64\n",
      "image_metas              shape: (1, 16)               min:    0.00000  max:  128.00000  int64\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP:  0.95\n"
     ]
    }
   ],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
